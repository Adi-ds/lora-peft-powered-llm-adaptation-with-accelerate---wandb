{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":54662,"databundleVersionId":6169864,"sourceType":"competition"},{"sourceId":6175087,"sourceType":"datasetVersion","datasetId":3540289}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from IPython.core.display import HTML\nHTML(\"\"\"\n<style>\n.output_png {\n    display: table-cell;\n    text-align: center;\n    vertical-align: middle;\n    horizontal-align: middle;\n}\nh1 {\n    text-align: center;\n    border-style: solid;\n    border-width: 3px;\n    background-color: #9467bd;\n    padding: 20px;\n    margin: 0;\n    color: black;\n    font-family: ariel;\n    border-radius: 80px;\n    border-color: #ff7f00;\n}\n\nh2 {\n    text-align: center;\n    border-style: solid;\n    border-width: 3px;\n    background-color: #de9ed6;\n    padding: 12px;\n    margin: 0;\n    color: black;\n    font-family: ariel;\n    border-radius: 80px;\n    border-color: #800080;\n}\n\nh3 {\n    text-align: center;\n    border-style: solid;\n    border-width: 3px;\n    background-color: #756bb1;\n    padding: 12px;\n    margin: 0;\n    color: black;\n    font-family: ariel;\n    border-radius: 80px;\n    border-color: #393b79;\n}\n\nbody, p {\n    font-family: ariel;\n    font-size: 18px;\n    color: black;\n}\ndiv {\n    font-size: 14px;\n    margin: 0;\n\n}\n\nh4 {\n    padding: 0px;\n    margin: 0;\n    font-family: ariel;\n    color: purple;\n}\n\n</style>\n\"\"\")","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-23T13:27:21.087286Z","iopub.execute_input":"2023-12-23T13:27:21.088539Z","iopub.status.idle":"2023-12-23T13:27:21.098723Z","shell.execute_reply.started":"2023-12-23T13:27:21.088490Z","shell.execute_reply":"2023-12-23T13:27:21.097287Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n.output_png {\n    display: table-cell;\n    text-align: center;\n    vertical-align: middle;\n    horizontal-align: middle;\n}\nh1 {\n    text-align: center;\n    border-style: solid;\n    border-width: 3px;\n    background-color: #9467bd;\n    padding: 20px;\n    margin: 0;\n    color: black;\n    font-family: ariel;\n    border-radius: 80px;\n    border-color: #ff7f00;\n}\n\nh2 {\n    text-align: center;\n    border-style: solid;\n    border-width: 3px;\n    background-color: #de9ed6;\n    padding: 12px;\n    margin: 0;\n    color: black;\n    font-family: ariel;\n    border-radius: 80px;\n    border-color: #800080;\n}\n\nh3 {\n    text-align: center;\n    border-style: solid;\n    border-width: 3px;\n    background-color: #756bb1;\n    padding: 12px;\n    margin: 0;\n    color: black;\n    font-family: ariel;\n    border-radius: 80px;\n    border-color: #393b79;\n}\n\nbody, p {\n    font-family: ariel;\n    font-size: 18px;\n    color: black;\n}\ndiv {\n    font-size: 14px;\n    margin: 0;\n\n}\n\nh4 {\n    padding: 0px;\n    margin: 0;\n    font-family: ariel;\n    color: purple;\n}\n\n:root {\n  --sequence-theme: hand\n}\n</style>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"# Preparing Ingredients to Cook: Creation of Data for LLM Training","metadata":{}},{"cell_type":"markdown","source":"Crafting the perfect training ground for Large Language Models (LLMs) is like preparing a recipe for success. Think of LLMs as hungry learners ready to feast on a diverse mix of data. It's not just about throwing words together; we carefully create prompts, like tasty instructions, to guide LLMs through different language tasks ‚Äì from simple summaries to more complex challenges. Once we have this flavorful mix of data, we divide it into training and validation sets. The training set is the main course, helping LLMs recognize language patterns, while the validation set ensures they truly understand the information. So, the secret sauce to LLM brilliance lies in this thoughtful blend of diverse data, purposeful prompts, and a bit of training and validation magic, paving the way for smarter communication and interaction down the road.","metadata":{}},{"cell_type":"markdown","source":"Contents:\n\n1. Importing Libraries and Dependencies\n2. Configurations\n3. Helper Functions\n\n    a. Joining data from different sources\n    \n    b. Preparing data with prompts\n    \n    c. Splitting data to training set and validation set\n  \n\nData Sources:\n1. [Kaggle - LLM Science Exam](https://www.kaggle.com/competitions/kaggle-llm-science-exam/leaderboard)\n2. [üìä6.5k train examples for LLM Science Examüìù](https://www.kaggle.com/datasets/radek1/additional-train-data-for-llm-science-exam)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T12:00:23.051173Z","iopub.execute_input":"2023-12-23T12:00:23.051627Z","iopub.status.idle":"2023-12-23T12:00:23.059637Z","shell.execute_reply.started":"2023-12-23T12:00:23.051584Z","shell.execute_reply":"2023-12-23T12:00:23.057679Z"}}},{"cell_type":"markdown","source":"## Flowchart for better understnading","metadata":{}},{"cell_type":"code","source":"import pydot\nfrom IPython.display import SVG\n\n\ndot_graph = pydot.Dot(graph_type='digraph')\n\ndata_src_1_node = pydot.Node('Data\\nSource\\n1')\ndata_src_1_node.set_shape('folder')\ndot_graph.add_node(data_src_1_node)\n\ndata_src_2_node = pydot.Node('Data\\nSource\\n2')\ndata_src_2_node.set_shape('folder')\ndot_graph.add_node(data_src_2_node)\n\ndata_merged_node = pydot.Node('Merged\\nData')\ndata_merged_node.set_shape('file')\ndot_graph.add_node(data_merged_node)\n\ndata_prompting_node = pydot.Node('Prompts\\nAdded')\ndata_prompting_node.set_shape('rect')\ndot_graph.add_node(data_prompting_node)\n\ndata_training_set_node = pydot.Node('Training\\nSet')\ndata_training_set_node.set_shape('circle')\ndot_graph.add_node(data_training_set_node)\n\ndata_testing_set_node = pydot.Node('Validation\\nSet')\ndata_testing_set_node.set_shape('circle')\ndot_graph.add_node(data_testing_set_node)\n\ndata_src_1_merge_edge = pydot.Edge(data_src_1_node, data_merged_node)\ndot_graph.add_edge(data_src_1_merge_edge)\n\ndata_src_2_merge_edge = pydot.Edge(data_src_2_node, data_merged_node)\ndot_graph.add_edge(data_src_2_merge_edge)\n\ndata_merge_prompt_edge = pydot.Edge(data_merged_node, data_prompting_node)\ndata_merge_prompt_edge.set_label('Adding\\nPrompts')\ndot_graph.add_edge(data_merge_prompt_edge)\n\ndata_prompt_train_edge = pydot.Edge(data_prompting_node, data_training_set_node)\ndot_graph.add_edge(data_prompt_train_edge)\n\ndata_prompt_test_edge = pydot.Edge(data_prompting_node, data_testing_set_node)\ndot_graph.add_edge(data_prompt_test_edge)\n\ndot_graph.write_svg('flow.svg')\nSVG('flow.svg')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-23T13:18:51.866981Z","iopub.execute_input":"2023-12-23T13:18:51.868127Z","iopub.status.idle":"2023-12-23T13:18:51.924359Z","shell.execute_reply.started":"2023-12-23T13:18:51.868077Z","shell.execute_reply":"2023-12-23T13:18:51.923042Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.SVG object>","image/svg+xml":"<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"256pt\" height=\"421pt\" viewBox=\"0.00 0.00 256.44 420.64\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 416.64)\">\n<title>G</title>\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-416.64 252.44,-416.64 252.44,4 -4,4\"/>\n<!-- Data\\nSource\\n1 -->\n<g id=\"node1\" class=\"node\">\n<title>Data\\nSource\\n1</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"110.49,-412.64 107.49,-416.64 86.49,-416.64 83.49,-412.64 44.99,-412.64 44.99,-352.89 110.49,-352.89 110.49,-412.64\"/>\n<text text-anchor=\"middle\" x=\"77.74\" y=\"-395.34\" font-family=\"Times,serif\" font-size=\"14.00\">Data</text>\n<text text-anchor=\"middle\" x=\"77.74\" y=\"-378.09\" font-family=\"Times,serif\" font-size=\"14.00\">Source</text>\n<text text-anchor=\"middle\" x=\"77.74\" y=\"-360.84\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n</g>\n<!-- Merged\\nData -->\n<g id=\"node3\" class=\"node\">\n<title>Merged\\nData</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"155.49,-315.89 83.99,-315.89 83.99,-273.39 155.49,-273.39 155.49,-315.89\"/>\n<text text-anchor=\"middle\" x=\"119.74\" y=\"-298.59\" font-family=\"Times,serif\" font-size=\"14.00\">Merged</text>\n<text text-anchor=\"middle\" x=\"119.74\" y=\"-281.34\" font-family=\"Times,serif\" font-size=\"14.00\">Data</text>\n</g>\n<!-- Data\\nSource\\n1&#45;&gt;Merged\\nData -->\n<g id=\"edge1\" class=\"edge\">\n<title>Data\\nSource\\n1-&gt;Merged\\nData</title>\n<path fill=\"none\" stroke=\"black\" d=\"M91.96,-352.61C96.13,-344.05 100.71,-334.67 104.92,-326.04\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"108.41,-327.86 109.65,-317.34 102.12,-324.79 108.41,-327.86\"/>\n</g>\n<!-- Data\\nSource\\n2 -->\n<g id=\"node2\" class=\"node\">\n<title>Data\\nSource\\n2</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"194.49,-412.64 191.49,-416.64 170.49,-416.64 167.49,-412.64 128.99,-412.64 128.99,-352.89 194.49,-352.89 194.49,-412.64\"/>\n<text text-anchor=\"middle\" x=\"161.74\" y=\"-395.34\" font-family=\"Times,serif\" font-size=\"14.00\">Data</text>\n<text text-anchor=\"middle\" x=\"161.74\" y=\"-378.09\" font-family=\"Times,serif\" font-size=\"14.00\">Source</text>\n<text text-anchor=\"middle\" x=\"161.74\" y=\"-360.84\" font-family=\"Times,serif\" font-size=\"14.00\">2</text>\n</g>\n<!-- Data\\nSource\\n2&#45;&gt;Merged\\nData -->\n<g id=\"edge2\" class=\"edge\">\n<title>Data\\nSource\\n2-&gt;Merged\\nData</title>\n<path fill=\"none\" stroke=\"black\" d=\"M147.52,-352.61C143.35,-344.05 138.77,-334.67 134.56,-326.04\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"137.36,-324.79 129.83,-317.34 131.07,-327.86 137.36,-324.79\"/>\n</g>\n<!-- Prompts\\nAdded -->\n<g id=\"node4\" class=\"node\">\n<title>Prompts\\nAdded</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"158.12,-202.89 81.37,-202.89 81.37,-160.39 158.12,-160.39 158.12,-202.89\"/>\n<text text-anchor=\"middle\" x=\"119.74\" y=\"-185.59\" font-family=\"Times,serif\" font-size=\"14.00\">Prompts</text>\n<text text-anchor=\"middle\" x=\"119.74\" y=\"-168.34\" font-family=\"Times,serif\" font-size=\"14.00\">Added</text>\n</g>\n<!-- Merged\\nData&#45;&gt;Prompts\\nAdded -->\n<g id=\"edge3\" class=\"edge\">\n<title>Merged\\nData-&gt;Prompts\\nAdded</title>\n<path fill=\"none\" stroke=\"black\" d=\"M119.74,-273.02C119.74,-256.43 119.74,-232.85 119.74,-213.94\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"123.24,-214.15 119.74,-204.15 116.24,-214.15 123.24,-214.15\"/>\n<text text-anchor=\"middle\" x=\"150.12\" y=\"-242.09\" font-family=\"Times,serif\" font-size=\"14.00\">Adding</text>\n<text text-anchor=\"middle\" x=\"150.12\" y=\"-224.84\" font-family=\"Times,serif\" font-size=\"14.00\">Prompts</text>\n</g>\n<!-- Training\\nSet -->\n<g id=\"node5\" class=\"node\">\n<title>Training\\nSet</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"53.74\" cy=\"-61.7\" rx=\"53.74\" ry=\"53.74\"/>\n<text text-anchor=\"middle\" x=\"53.74\" y=\"-65.65\" font-family=\"Times,serif\" font-size=\"14.00\">Training</text>\n<text text-anchor=\"middle\" x=\"53.74\" y=\"-48.4\" font-family=\"Times,serif\" font-size=\"14.00\">Set</text>\n</g>\n<!-- Prompts\\nAdded&#45;&gt;Training\\nSet -->\n<g id=\"edge4\" class=\"edge\">\n<title>Prompts\\nAdded-&gt;Training\\nSet</title>\n<path fill=\"none\" stroke=\"black\" d=\"M108.24,-160.1C101.7,-148.4 93.15,-133.13 84.78,-118.16\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"87.54,-116.94 79.61,-109.92 81.44,-120.35 87.54,-116.94\"/>\n</g>\n<!-- Validation\\nSet -->\n<g id=\"node6\" class=\"node\">\n<title>Validation\\nSet</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"186.74\" cy=\"-61.7\" rx=\"61.7\" ry=\"61.7\"/>\n<text text-anchor=\"middle\" x=\"186.74\" y=\"-65.65\" font-family=\"Times,serif\" font-size=\"14.00\">Validation</text>\n<text text-anchor=\"middle\" x=\"186.74\" y=\"-48.4\" font-family=\"Times,serif\" font-size=\"14.00\">Set</text>\n</g>\n<!-- Prompts\\nAdded&#45;&gt;Validation\\nSet -->\n<g id=\"edge5\" class=\"edge\">\n<title>Prompts\\nAdded-&gt;Validation\\nSet</title>\n<path fill=\"none\" stroke=\"black\" d=\"M131.41,-160.1C137.02,-150.22 144.08,-137.79 151.26,-125.15\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"154.6,-127.37 156.49,-116.94 148.51,-123.91 154.6,-127.37\"/>\n</g>\n</g>\n</svg>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Importing Libraries and Dependencies","metadata":{}},{"cell_type":"code","source":"import gc\nimport os\nimport pandas as pd\npd.set_option('display.max_colwidth', 500)\n\nfrom tqdm import tqdm\nfrom string import Template\nfrom dataclasses import dataclass","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating Configurations","metadata":{}},{"cell_type":"code","source":"@dataclass(frozen=True)\nclass Config:\n    PWD = os.getcwd()\n    TRAIN_FILE_FROM_COMPETITION: str='/kaggle/input/kaggle-llm-science-exam/train.csv'\n    EXTRA_EXAMPLES: str='/kaggle/input/additional-train-data-for-llm-science-exam/extra_train_set.csv'\n    TRAIN_EXAMPLES_6K: str='/kaggle/input/additional-train-data-for-llm-science-exam/6000_train_examples.csv'\n    FINAL_DATA_SAMPLES_TO_DISPLAY: int=5\n    SPLIT_DATA: bool=True\n    SAVE_MERGED_DATA: bool=True\n    MERGED_DATA_NAME: str='final_data.csv'\n    TRAINING_RATIO: float=0.75\n    TRAIN_CSV_FILE_NAME: str='final_training_data.csv'\n    VALID_CSV_FILE_NAME: str='final_validation_data.csv'\n    SEQUENCE_MAX_LENGTH: int=2**12","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Helper Functions","metadata":{}},{"cell_type":"markdown","source":"### Function to merge dataframes from different sources","metadata":{}},{"cell_type":"code","source":"def merge_data_sources():\n    \"\"\"\n    Merges and preprocesses data from different sources to create a consolidated dataframe for training models.\n\n    Reads the following datasets:\n    1. train.csv from competition data.\n    2. 6000_train_examples.csv from 6.5k train examples for LLM Science Exam.\n    3. extra_train_set.csv from additional 6.5k train examples for LLM Science Exam.\n\n    Drops the 'id' column from the competition data.\n    Aligns column names and concatenates the three dataframes into a single dataframe for model training.\n    \n    Displays information about the size of each dataframe (number of rows) for verification.\n    Displays a sample of the final merged dataframe for visual inspection.\n    \n    Checks for and prints the number of duplicate rows present in the final dataset.\n\n    Cleans up memory by deleting intermediate dataframes.\n\n    Returns:\n    - df: Final merged dataframe for model training.\n    \"\"\"\n    # Read train.csv from competition data\n    df1 = pd.read_csv(Config.TRAIN_FILE_FROM_COMPETITION)\n    df1.drop(columns=['id'], inplace=True)\n    column_names = df1.columns\n\n    # Read 6000_train_examples.csv from 6.5k train examples for LLM Science Exam \n    df2 = pd.read_csv(Config.TRAIN_EXAMPLES_6K)\n    df2 = df2[column_names]\n\n    # Read extra_train_set.csv from 6.5k train examples for LLM Science Exam \n    df3 = pd.read_csv(Config.EXTRA_EXAMPLES)\n    df3 = df3[column_names]\n\n    # # Join the three dataframes to obtain a single dataframe  on which models will be trained\n    df = pd.concat([df1, df2, df3], axis=0, ignore_index=True)\n    df.reset_index(inplace=True, drop=True)\n\n    # # Check if properly joined\n    display(\n        pd.DataFrame(\n            data = {\n                'Dataframes' : ['train.csv from competition data', '6000_train_examples.csv from 6.5k train examples for LLM Science Exam', 'extra_train_set.csv from 6.5k train examples for LLM Science Exam ', 'Final Training Dataframe'],\n                'Number of rows' : [len(df1),len(df2),len(df3),len(df)]\n            }\n        ).style.set_caption(\"Dataframe Sizes\")\n    )\n\n    print('\\n')\n\n    # Display Sample Rows from Merged Data\n    display(\n        df.sample(Config.FINAL_DATA_SAMPLES_TO_DISPLAY).style.set_caption(\n            f\"Final Merged Dataframe ({Config.FINAL_DATA_SAMPLES_TO_DISPLAY} Sampled rows)\"\n        )\n    )\n\n    print(f'\\nNumber of duplicate rows present in the final dataset: {df.duplicated().sum()}')\n    \n    del df1\n    del df2\n    del df3\n    gc.collect()\n\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Making Prompts out of Data","metadata":{}},{"cell_type":"code","source":"def prepare_final_df(\n        data: pd.DataFrame,\n        instruction: str='As your response to the prompt, select the most appropriate option among A, B, C, D, and E.'\n    ):\n     \"\"\"\n    Prepares the final dataframe with formatted prompts and answers.\n\n    Args:\n    - data (pd.DataFrame): Input dataframe containing prompt information.\n    - instruction (str): Instruction to be included in the prompts.\n\n    Returns:\n    - pd.DataFrame: Final dataframe with formatted prompts and answers.\n    \"\"\"\n    \n    def prepare_final_prompt(\n            row_data: pd.core.series.Series,\n            instruction: str=instruction\n        ):\n        \"\"\"\n        Prepares a final prompt by formatting the instruction, prompt, options (A-E), and the correct answer.\n\n        Args:\n        - row_data (pd.core.series.Series): Data for a single row containing prompt details.\n        - instruction (str): Instruction to be included in the prompts.\n\n        Returns:\n        - str: Formatted final prompt.\n        \"\"\"\n        try:\n            template = Template(\n                            '### Instruction: \\n \\\n                             $instruction \\n\\n   \\\n                             ### Prompt \\n       \\\n                             $prompt \\n\\n        \\\n                             A) $a \\n            \\\n                             B) $b \\n            \\\n                             C) $c \\n            \\\n                             D) $d \\n            \\\n                             E) $e \\n\\n          \\\n                             ### Answer:\\n     \\\n                             $ans'\n                        )\n            final_prompt = template.substitute(\n                                instruction = instruction,\n                                prompt = row_data['prompt'],\n                                a = row_data['A'],\n                                b = row_data['B'],\n                                c = row_data['C'],\n                                d = row_data['D'],\n                                e = row_data['E'],\n                                ans = row_data['answer']\n                            )\n            \n            del row_data\n            gc.collect()\n            \n            return final_prompt\n        except Exception as e:\n            raise(e)\n\n    def select_prompts_with_a_max_length(\n            data: pd.DataFrame,\n            max_length: int=Config.SEQUENCE_MAX_LENGTH\n        ):\n        \"\"\"\n        Selects prompts with a maximum length less than the specified value.\n\n        Args:\n        - data (pd.DataFrame): Input dataframe containing prompt details.\n        - max_length (int): Maximum length allowed for prompts.\n\n        Returns:\n        - pd.DataFrame: Dataframe with selected prompts.\n        \"\"\"\n        try:\n            keep_indices = []\n            for index, prompt in tqdm(\n                                        data.iterrows(),\n                                        desc='Fetching Indices to keep',\n                                        total=data.shape[1]\n                                   ):\n                text_sequence_length = len(data['final_prompts'][index])\n                if text_sequence_length < max_length:\n                    keep_indices.append(int(index))\n\n            # Select the indices\n            data = data.loc[keep_indices]\n            data.reset_index(drop=True, inplace=True)\n            return data\n        except Exception as e:\n            raise(e)\n\n    try:\n        # Prepare the final prompts\n        final_prompts = []\n        for idx, row_data in tqdm(\n                                    data.iterrows(), \n                                    desc='Creating final prompts',\n                                    total=data.shape[1]\n                             ):\n            final_prompts.append(\n                    prepare_final_prompt(row_data=row_data)\n            )\n\n        # Prepare the final answers\n        final_answers = data['answer'] # encode_answers(data=data)\n        final_data = pd.DataFrame(\n                        data={\n                                'final_prompts':final_prompts,\n                                'final_answers':final_answers\n                            }\n                        )\n        final_data = select_prompts_with_a_max_length(final_data)\n\n        display(\n            final_data.sample(Config.FINAL_DATA_SAMPLES_TO_DISPLAY).style.set_caption(\"Final Data with Prompts\")\n        )\n\n        if Config.SAVE_MERGED_DATA:\n            final_data.to_csv(Config.MERGED_DATA_NAME, index=False)\n            print(f'\\nSaving Data to {Config.PWD}/{Config.MERGED_DATA_NAME}')\n\n        del data\n        gc.collect()\n\n        return final_data\n    except Exception as e:\n        raise(e)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Creating Data","metadata":{}},{"cell_type":"code","source":"def train_valid(df:pd.DataFrame):\n    \"\"\"\n    Splits the dataframe into training and validation sets and saves them as CSV files.\n\n    Args:\n    - df (pd.DataFrame): Input dataframe containing training and validation data.\n\n    Raises:\n    - Exception: If an error occurs during the process.\n    \"\"\"\n    try:\n        if Config.SPLIT_DATA:\n\n            for i in tqdm(range(1), desc='\\nSplitting merged data'):\n                train_df = df[: int(len(df)*Config.TRAINING_RATIO)]\n                valid_df = df[int(len(df)*Config.TRAINING_RATIO)+1:]\n\n            for i in tqdm(range(1), desc=f'\\nSaving final training data to {Config.PWD}/{Config.TRAIN_CSV_FILE_NAME}'):\n                train_df.to_csv(Config.TRAIN_CSV_FILE_NAME, index=False)\n                display(\n                    train_df.sample(Config.FINAL_DATA_SAMPLES_TO_DISPLAY).style.set_caption(\"Final Training Data with Prompts\")\n                )\n\n            for i in tqdm(range(1), desc=f'\\nSaving final validation data to {Config.PWD}/{Config.VALID_CSV_FILE_NAME}'):\n                valid_df.to_csv(Config.VALID_CSV_FILE_NAME, index=False)\n                display(\n                    valid_df.sample(Config.FINAL_DATA_SAMPLES_TO_DISPLAY).style.set_caption(\"Final Validation Data with Prompts\")\n                )\n                \n            del train_df\n            del valid_df\n            gc.collect()\n\n        del df\n        gc.collect()\n        \n    except Exception as e:\n        raise(e)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preparation of Ingredients (data)","metadata":{}},{"cell_type":"code","source":"df = merge_data_sources()\ndf = prepare_final_df(df)\ntrain_valid(df)","metadata":{"_uuid":"20dc6f74-e543-4c30-877f-90611bd80eb4","_cell_guid":"63bc4c21-99f1-492a-82f5-b0dbecd13eab","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Storiing Ingredients (data) for cooking","metadata":{}},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'/kaggle/working/final_data.csv')\nFileLink(r'/kaggle/working/final_training_data.csv')\nFileLink(r'/kaggle/working/final_validation_data.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Next Steps","metadata":{}},{"cell_type":"markdown","source":"[Cooking](https://www.kaggle.com/code/adityadawn/training-llm-using-accelerate-and-w-b?scriptVersionId=156219026)\n\nServing","metadata":{}},{"cell_type":"markdown","source":"Special Mention: [Flowcharts PyDot](https://www.kaggle.com/code/kmader/flowcharts-pydot#Data-Flow-LungStage)","metadata":{}},{"cell_type":"markdown","source":"# Please upvote if you like","metadata":{}}]}